import os
import glob
import pandas as pd
import json
import re
from datetime import datetime
import urllib.request
import urllib.error

# ==============================================================================
# 1. ì„¤ì • (Configuration)
# ==============================================================================
RAW_DATA_DIR = os.path.join(os.getcwd(), "raw_data")
OUTPUT_FILE = os.path.join(os.getcwd(), "assets", "model_constants.js")
# ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ê²½ë¡œ (í•„ìš” ì‹œ ìˆ˜ì •)
OUTPUT_FILE_DESKTOP = r"C:\Users\ë°•ë‚¨ìˆœ\OneDrive\Desktop\gimpo-goldline\assets\model_constants.js"

LAT = 37.615
LON = 126.715

# [í•„ìˆ˜] ê³µíœ´ì¼ ë°ì´í„°
HOLIDAYS = set([
    "2024-01-01", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12",
    "2024-03-01", "2024-04-10",
    "2024-05-05", "2024-05-06", "2024-05-15",
    "2024-06-06", "2024-08-15", "2024-09-16", "2024-09-17", "2024-09-18",
    "2024-10-03", "2024-10-09", "2024-12-25",
    "2025-01-01", "2025-01-27", "2025-01-28", "2025-01-29", "2025-01-30"
])

def get_holiday_status(date_str):
    if date_str in HOLIDAYS: return 'Holiday'
    try:
        dt = datetime.strptime(date_str, "%Y-%m-%d")
        if dt.weekday() >= 5: return 'Holiday'
    except: pass
    return 'Workday'

# WMO ì½”ë“œ ë³€í™˜ (ë‹¨ìˆœí™”)
def convert_wmo(code):
    if code is None: return "Clear"
    if 71 <= code <= 77 or 85 <= code <= 86: return "Snow"
    if code >= 51: return "Rain"
    return "Clear"

# ==============================================================================
# 2. ë‚ ì”¨ ìˆ˜ì§‘ í•¨ìˆ˜ (ê³¼ê±° + ë¯¸ë˜ 7ì¼)
# ==============================================================================
def fetch_historical_weather(start_date, end_date):
    """ê³¼ê±° ë‚ ì”¨ (í•™ìŠµìš©)"""
    print(f"ğŸŒ¦ï¸ [ê³¼ê±°] ë‚ ì”¨ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ({start_date} ~ {end_date})")
    url = f"https://archive-api.open-meteo.com/v1/archive?latitude={LAT}&longitude={LON}&start_date={start_date}&end_date={end_date}&daily=weather_code&timezone=Asia%2FSeoul"
    try:
        with urllib.request.urlopen(url) as response:
            if response.status != 200: raise Exception(f"HTTP {response.status}")
            data = json.loads(response.read().decode())
            
            weather_map = {}
            if 'daily' in data:
                dates = data['daily']['time']
                codes = data['daily']['weather_code']
                for d, c in zip(dates, codes):
                    weather_map[d] = convert_wmo(c)
            return weather_map
    except Exception as e:
        print(f"âš ï¸ ê³¼ê±° ë‚ ì”¨ ì‹¤íŒ¨: {e}")
        return None

def fetch_7day_forecast():
    """[NEW] ë¯¸ë˜ 7ì¼ ì˜ˆë³´ (ì‹¤ì „ìš©)"""
    print(f"ğŸ”® [ë¯¸ë˜] 7ì¼ê°„ì˜ ì¼ê¸°ì˜ˆë³´ ìˆ˜ì§‘ ì¤‘...")
    url = f"https://api.open-meteo.com/v1/forecast?latitude={LAT}&longitude={LON}&daily=weather_code&timezone=Asia%2FSeoul&forecast_days=7"
    try:
        with urllib.request.urlopen(url) as response:
            if response.status != 200: raise Exception(f"HTTP {response.status}")
            data = json.loads(response.read().decode())
            
            forecast_map = {}
            if 'daily' in data:
                dates = data['daily']['time']
                codes = data['daily']['weather_code']
                for d, c in zip(dates, codes):
                    forecast_map[d] = convert_wmo(c)
            
            print(f"âœ… 7ì¼ ì˜ˆë³´ í™•ë³´: {len(forecast_map)}ì¼ì¹˜")
            return forecast_map
    except Exception as e:
        print(f"âš ï¸ ì˜ˆë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return {}

# ==============================================================================
# 3. ë©”ì¸ ë¡œì§
# ==============================================================================
def run_extraction():
    print("ğŸš€ Model Generator ì‹œì‘ (Hybrid: Past + Future)")
    
    csv_files = glob.glob(os.path.join(RAW_DATA_DIR, "**", "*.csv"), recursive=True)
    if not csv_files:
        print("âŒ CSV íŒŒì¼ ì—†ìŒ.")
        return

    # 1. ë‚ ì§œ ë²”ìœ„ íŒŒì•…
    all_dates = []
    for fpath in csv_files:
        try:
            df = pd.read_csv(fpath, encoding='cp949', usecols=[2])
            dates = [d.split('(')[0].strip() for d in df.iloc[:, 0].astype(str).tolist() if '-' in str(d)]
            all_dates.extend(dates)
        except: continue
        
    if not all_dates: return
    all_dates.sort()
    start_date, end_date = all_dates[0], all_dates[-1]

    # 2. ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘
    history_weather = fetch_historical_weather(start_date, end_date)
    future_forecast = fetch_7day_forecast() # [ì¶”ê°€ëœ ê¸°ëŠ¥]

    if history_weather is None: return 

    # 3. ë°ì´í„° ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    base_data = {} 
    monthly_totals = {}
    weather_totals = { "Peak": {}, "Off": {} } # [NEW] ì‹œê°„ëŒ€ë³„ ë¶„ë¦¬ 
    
    for fpath in csv_files:
        try:
            df = pd.read_csv(fpath, encoding='cp949')
            for index, row in df.iterrows():
                try:
                    station = str(row.iloc[0]).split('[')[0].strip()
                    if station == "nan": continue
                    date_only = str(row.iloc[2]).split('(')[0].strip()
                    dt = datetime.strptime(date_only, "%Y-%m-%d")
                    day_type = get_holiday_status(date_only)
                    weather = history_weather.get(date_only, "Clear")
                    
                    if station not in base_data: base_data[station] = { 'Workday': {}, 'Holiday': {} }
                    
                    col_idx = 3
                    while col_idx < len(df.columns) - 1:
                        if not re.search(r'(\d+)', str(df.columns[col_idx])): 
                            col_idx += 2; continue
                        hour = int(re.search(r'(\d+)', str(df.columns[col_idx])).group(1))
                        try: board = int(row.iloc[col_idx]); alight = int(row.iloc[col_idx+1])
                        except: board=0; alight=0
                        
                        # [Correction] Removed hardcoded 5.0x multiplier. Now using Bathtub Theory post-processing.
                        if False: # Legacy Code
                            if station == 'ê¹€í¬ê³µí•­':
                                board = int(board * 5.0)
                                alight = int(alight * 5.0)
                        
                        if hour not in base_data[station][day_type]:
                            base_data[station][day_type][hour] = {'b': [], 'a': []}
                        base_data[station][day_type][hour]['b'].append(board)
                        base_data[station][day_type][hour]['a'].append(alight)
                        
                        if dt.month not in monthly_totals: monthly_totals[dt.month] = []
                        monthly_totals[dt.month].append(board)
                        
                        # [NEW] ì‹œê°„ëŒ€ë³„ ë‚ ì”¨ ì˜í–¥ ë¶„ë¦¬ (Peak vs Off)
                        # ì¶œê·¼(06:30~08:30) -> 6,7,8ì‹œ / í‡´ê·¼(17:30~19:30) -> 17,18,19ì‹œ
                        is_peak = (6 <= hour <= 8) or (17 <= hour <= 19)
                        period = "Peak" if is_peak else "Off"
                        
                        if weather not in weather_totals[period]: weather_totals[period][weather] = []
                        weather_totals[period][weather].append(board)
                        
                        col_idx += 2
                except: continue
        except: continue

    # ê³„ìˆ˜ ì‚°ì¶œ
    base_load_final = {}
    for st, days in base_data.items():
        base_load_final[st] = {}
        for dtype, hours in days.items():
            base_load_final[st][dtype] = {}
            for h, vals in hours.items():
                avg_b = sum(vals['b'])/len(vals['b']) if vals['b'] else 0
                avg_a = sum(vals['a'])/len(vals['a']) if vals['a'] else 0
                base_load_final[st][dtype][h] = {'b': round(avg_b), 'a': round(avg_a)}

    # [Bathtub Theory] Gimpo Airport Boarding = Sum(Others Alighting)
    # Reason: Gimpo Airport boarding data is missing transfer passengers. 
    # Logic: In a closed system, total alighting at other stations must have originated from Gimpo (for the return leg).
    for dtype in ['Workday', 'Holiday']:
        # Assuming hours 5 to 0 (24h coverage)
        all_hours = set()
        for h_map in base_load_final.values():
             if dtype in h_map: all_hours.update(h_map[dtype].keys())
        
        for h in all_hours:
            total_alight_others = 0
            for st in base_load_final:
                if st == 'ê¹€í¬ê³µí•­': continue
                if dtype in base_load_final[st] and h in base_load_final[st][dtype]:
                    total_alight_others += base_load_final[st][dtype][h]['a']
            
            # Apply to Gimpo Airport
            if 'ê¹€í¬ê³µí•­' in base_load_final and dtype in base_load_final['ê¹€í¬ê³µí•­']:
                # Ensure hour key exists
                if h not in base_load_final['ê¹€í¬ê³µí•­'][dtype]:
                    base_load_final['ê¹€í¬ê³µí•­'][dtype][h] = {'b': 0, 'a': 0}
                
                # Overwrite Boarding
                base_load_final['ê¹€í¬ê³µí•­'][dtype][h]['b'] = total_alight_others

    yearly_avg = sum(sum(vs) for vs in monthly_totals.values()) / sum(len(vs) for vs in monthly_totals.values()) if monthly_totals else 1
    seasonal_factors = {m: round((sum(monthly_totals[m])/len(monthly_totals[m])) / yearly_avg, 2) for m in monthly_totals} if monthly_totals else {}
    for m in range(1,13): 
        if m not in seasonal_factors: seasonal_factors[m] = 1.0

    # [NEW] ì‹œê°„ëŒ€ë³„ ë‚ ì”¨ ê³„ìˆ˜ ì‚°ì¶œ
    weather_factors = {}
    all_weather_types = set(list(weather_totals["Peak"].keys()) + list(weather_totals["Off"].keys()))
    
    for w in all_weather_types:
        weather_factors[w] = {}
        for p in ["Peak", "Off"]:
            # í•´ë‹¹ ì‹œê°„ëŒ€(p)ì˜ 'Clear' í‰ê·  êµ¬í•˜ê¸° (ê¸°ì¤€ì )
            base_list = weather_totals[p].get("Clear", [])
            base_avg = sum(base_list)/len(base_list) if base_list else 1.0
            
            # í•´ë‹¹ ë‚ ì”¨(w)ì˜ í‰ê·  êµ¬í•˜ê¸°
            target_list = weather_totals[p].get(w, [])
            target_avg = sum(target_list)/len(target_list) if target_list else base_avg
            
            # ê³„ìˆ˜ = (íŠ¹ì •ë‚ ì”¨ í‰ê·  / ë§‘ì€ë‚  í‰ê· )
            factor = round(target_avg / base_avg, 2)
            weather_factors[w][p] = factor

    # 4. ì €ì¥ (FORECAST í¬í•¨)
    output_obj = {
        "BASE_LOAD": base_load_final,
        "SEASON_FACTORS": seasonal_factors,
        "WEATHER_FACTORS": weather_factors,
        "FORECAST": future_forecast,  # [í•µì‹¬] ì—¬ê¸°ì— ë¯¸ë˜ 7ì¼ ë‚ ì”¨ê°€ ì €ì¥ë©ë‹ˆë‹¤
        "META": { "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S") }
    }
    
    js_content = "const MODEL_CONSTANTS = " + json.dumps(output_obj, ensure_ascii=False, indent=4) + ";"
    
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f: f.write(js_content)
        print(f"Success: Updated {OUTPUT_FILE}")
    except Exception as e: print(f"Error: {e}")
    
    try:
        if os.path.exists(os.path.dirname(OUTPUT_FILE_DESKTOP)):
            with open(OUTPUT_FILE_DESKTOP, 'w', encoding='utf-8') as f: f.write(js_content)
    except: pass

if __name__ == "__main__":
    run_extraction()